---
title: "Useful Things"
sitemap:
  changefreq: monthly
  lastmod: '2017-05-08T12:49:30-05:00'
  priority: 0.5
layout: default
---

  
This page (currently under construction) hosts a collection of tools that I have found useful as an student/RA, mostly in the realm of data scraping. The hope is that some RA will stumble across this and save herself 200 hours of coyping data from pdfs. 

**Beautiful Soup**

[Beautifulsoup](https://www.crummy.com/software/BeautifulSoup/?) is a python library for scraping HTML/XML. Pretty neat.  

**PDF Miner**

Not all data is in HTML. Pros: you can get data from PDFs! Cons: Must be local. [Here](https://media.readthedocs.org/pdf/pdfminer-docs/latest/pdfminer-docs.pdf) is  the super boring to read documentation... a more friendly tutorial is coming soon.  
  
  
**Amazon EC2 Instances**  
  
Amazon offers super cheap (+ 1 year free!) cloud computing services. Why do you want to use this? You a) don't have access to your own server b) don't have a laptop you can devote to scraping 24/7. 

If you want to scrape weather data for Ulaanbaatar every 60 seconds day in and day out, you should set up an Amazon EC2 instance. This will act as your own personal server. 

Once you are set up, [connect to your amazon EC2 instance](https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/AccessingInstancesLinux.html) using the terminal app. Then use the [screen](https://kb.iu.edu/d/acuy) command to run your scraper. This will keep your code running even after you disconnect from youe EC2 instance, even after you shut down your computer, even after you throw your computer off a bridge, etc, etc. 

Desafortunadamente the documentation for EC2 instances is, well, poor. Stackoverflow is your friend. 



**Virtual Environments**

Virtual environments are good practice when using python. This is because your projects may require a specific versions of a python library (like beautifulsoup!), and when you download libraries using, say, pip, they are just plopped into the site-packages directory. 
Virtual environments create an isolated set of directories that help you prevent these conflicts. So in general, if you have a project you should create a virtual environment specific to that project. 
More on virtual environments [here](http://docs.python-guide.org/en/latest/dev/virtualenvs/) and [here](https://realpython.com/python-virtual-environments-a-primer/)


```{r engine = 'bash', eval = FALSE}
pip install virtualenv
cd my_project_folder
virtualenv venv_my_project
```


  


